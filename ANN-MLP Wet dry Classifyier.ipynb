{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data..\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_root = \"/home/cmlare/Data/RF Data/Processed/\"\n",
    "# rainfall_mapped_df_1 = pd.read_csv(data_root+\"2018-05-08 to 2018-05-15_integrated.csv\")\n",
    "print(\"Loading Data..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_types = [\"FrequencyBand\",\"PathLength\",\"wet_dry\",\"RSL_AVG\",\"RSL_MIN\",\"RSL_MAX\",\"TSL_MAX\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_classified_1 = pd.read_csv(data_root+\"2018-05-08 to 2018-05-15_integrated_classified.csv\")\n",
    "rainfall_classified_2 = pd.read_csv(data_root+\"2018-05-16 to 2018-05-23_integrated_classified.csv\")\n",
    "rainfall_classified_3 = pd.read_csv(data_root+\"2018-05-24 to 2018-05-31_integrated_classified.csv\")\n",
    "rainfall_classified_4 = pd.read_csv(data_root+\"2018-06-01 to 2018-06-10_integrated_classified.csv\")\n",
    "rainfall_classified = pd.concat([rainfall_classified_1, rainfall_classified_2, rainfall_classified_3,rainfall_classified_3,rainfall_classified_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_classified[\"wet_dry\"] = rainfall_classified[\"class\"].map({\"A\":\"DRY\",\"B\":\"WET\",\"C\":\"WET\",\"D\":\"WET\",\"E\":\"WET\",\"F\":\"WET\",\"G\":\"WET\",\"H\":\"WET\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_classified[\"Baseline_ATTN\"] = rainfall_classified[\"Baseline\"].sub(rainfall_classified[\"RSL_MIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = rainfall_classified[selected_feature_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_classified_test_data = pd.read_csv(data_root+\"2018-06-11 to 2018-07-07_integrated_classified.csv\")\n",
    "rainfall_classified_test_data[\"wet_dry\"] = rainfall_classified_test_data[\"class\"].map({\"A\":\"DRY\",\"B\":\"WET\",\"C\":\"WET\",\"D\":\"WET\",\"E\":\"WET\",\"F\":\"WET\",\"G\":\"WET\",\"H\":\"WET\"})\n",
    "rainfall_classified_test_data[\"Baseline_ATTN\"] = rainfall_classified_test_data[\"Baseline\"].sub(rainfall_classified_test_data[\"RSL_MIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = selected_features.drop(['wet_dry'],axis = 1)\n",
    "y = selected_features['wet_dry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Preprocessing **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting data..\n",
      "Data fitting finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "print(\"Fitting data..\")\n",
    "# scaler.fit(X_train)\n",
    "scaler.fit(X)\n",
    "print(\"Data fitting finished.\")\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "# Now apply the transformations to the data:\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model..\n",
      "Model training finished.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500,activation=\"logistic\")\n",
    "print(\"Training the model..\")\n",
    "# mlp.fit(X_train,y_train)\n",
    "mlp.fit(X,y)\n",
    "print(\"Model training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Predictions and evaluation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Predictions on train data..\n",
      "Running predictions finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Predictions on train data..\")\n",
    "# predictions = mlp.predict(X_test)\n",
    "predictions = mlp.predict(X)\n",
    "print(\"Running predictions finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[385841   5641]\n",
      " [ 19491  12917]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "# print(confusion_matrix(y_test,predictions))\n",
    "print(confusion_matrix(y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        DRY       0.95      0.99      0.97    391482\n",
      "        WET       0.70      0.40      0.51     32408\n",
      "\n",
      "avg / total       0.93      0.94      0.93    423890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_test,predictions))\n",
    "print(classification_report(y,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Saving the Model ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /home/cmlare/Data/Models/mlp_ANN_wet_dry_h-13_RSL_MIN,RSL_MAX,RSL_AVG.sav\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = \"/home/cmlare/Data/Models/\"+'mlp_ANN_wet_dry h-13 RSL_MIN,RSL_MAX,RSL_AVG,TSL_MAX L-100.sav'\n",
    "print(\"Saving model to \"+ filename)\n",
    "pickle.dump(mlp, open(filename, 'wb'))\n",
    "print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test Data prediction **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting test data..\n",
      "Test data fitting finished.\n",
      "Running Predictions on test data..\n",
      "Running predictions on test data finished.\n"
     ]
    }
   ],
   "source": [
    "selected_features_test = rainfall_classified_test_data[selected_feature_types]\n",
    "X_test = selected_features_test.drop(['wet_dry'],axis = 1)\n",
    "y_test = selected_features_test['wet_dry']\n",
    "\n",
    "print(\"Fitting test data..\")\n",
    "scaler.fit(X_test)\n",
    "print(\"Test data fitting finished.\")\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "# Now apply the transformations to the data:\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Running Predictions on test data..\")\n",
    "predictions_test = mlp.predict(X_test)\n",
    "print(\"Running predictions on test data finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182196   4024]\n",
      " [  2955   1975]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        DRY       0.98      0.98      0.98    186220\n",
      "        WET       0.33      0.40      0.36      4930\n",
      "\n",
      "avg / total       0.97      0.96      0.97    191150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classification_report = classification_report(y_test,predictions_test)\n",
    "print(test_classification_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
